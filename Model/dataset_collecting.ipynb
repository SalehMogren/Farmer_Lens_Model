{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28533e12",
   "metadata": {},
   "source": [
    "# Creating Dates Dataset \n",
    "\n",
    "this notebook is used for collecting and classifiying dates dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6786a005",
   "metadata": {},
   "source": [
    "## Collecting Datasets\n",
    "\n",
    "Using Selenium webDriver for fetching images from googlethe documentaion can be found [here](https://www.selenium.dev/selenium/docs/api/py/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc43da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install Selenium\n",
    "!pip install -U selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cb457cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saleh\\AppData\\Local\\Temp/ipykernel_14712/280538312.py:10: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(\"C:\\\\My Projects\\\\webDrivers\\\\chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from PIL import Image\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time \n",
    "from urllib import request\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "#Opens up web driver and goes to Google Images\n",
    "driver = webdriver.Chrome(\"C:\\\\My Projects\\\\webDrivers\\\\chromedriver.exe\")\n",
    "header={'User-Agent':\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.134 Safari/537.36\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "851c12b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = {'Ajwa':'Ajwa date',\n",
    "           'Sokari':'Sokari dates',\n",
    "            'Medjool':'medjool dates , تمر مجدول',\n",
    "            'Nabtat Ali':'nabtat ali dates , تمر نبته علي',\n",
    "            'Shaishe':'تمر شيشي',\n",
    "            'Sugaey':'تمر صقعي',\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abb9bd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directories\n",
    "\n",
    "parent_dir = \"{0}\\\\dates_dataset\\\\dataset_collected_google_images\".format(os.getcwd())\n",
    "for keyword in keywords:\n",
    "    path = os.path.join(parent_dir, keyword)\n",
    "    if(os.path.isdir(path)):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(path)\n",
    "        print(\"Directory '% s' created\" % keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "783e2001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_google_images (keyword,limit,query):\n",
    "    driver.get('https://www.google.com.sa/imghp?hl=ar&ogbl')\n",
    "    # Search box \n",
    "    inputBox = driver.find_element_by_xpath('//*[@id=\"sbtc\"]/div/div[2]/input')\n",
    "    inputBox.send_keys(query)\n",
    "    inputBox.send_keys(Keys.ENTER)\n",
    "\n",
    "    #Will keep scrolling down the webpage until it cannot scroll no more\n",
    "    last_height = driver.execute_script('return document.body.scrollHeight')\n",
    "    while True:\n",
    "        driver.execute_script('window.scrollTo(0,document.body.scrollHeight)')\n",
    "        time.sleep(2)\n",
    "        new_height = driver.execute_script('return document.body.scrollHeight')\n",
    "        try:\n",
    "            driver.find_element_by_xpath('//*[@id=\"islmp\"]/div/div/div/div/div[5]/input').click()\n",
    "            time.sleep(2)\n",
    "        except:\n",
    "            pass\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    \"\"\"\n",
    "    Finding xpath patterns for images \n",
    "    first image = //*[@id=\"islrg\"]/div[1]/div[3]/a[1]/div[1]/img\n",
    "    second image = //*[@id=\"islrg\"]/div[1]/div[2]/a[1]/div[1]/img\n",
    "\n",
    "    second div is chainging \n",
    "\n",
    "    \"\"\"\n",
    "    path = os.path.join(parent_dir, keyword)\n",
    "    successCounter = 0\n",
    "    images = []\n",
    "    for i in range(limit):\n",
    "        try:\n",
    "            img = driver.find_element_by_xpath('//*[@id=\"islrg\"]/div[1]/div['+str(i)+']/a[1]/div[1]/img')\n",
    "            images.append(img)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    print('Number of scraped images:', len(images))\n",
    "    \n",
    "    for image in images:\n",
    "        try:\n",
    "            image.screenshot(os.path.join(path ,str(successCounter) + \"_2nd_.\" + 'jpg'))\n",
    "            successCounter  += 1\n",
    "        except:\n",
    "            print (\"can't get img\")\n",
    "    print('Number of saved images : ',successCounter)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c9c357",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,val in keywords.items():\n",
    "    print('Fetching {} images ..'.format(key))\n",
    "    search_google_images(key,400,val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39bf94c",
   "metadata": {},
   "source": [
    "### Clean dataset\n",
    "Dataset after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c13cfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Ajwa : 530\n",
      "Number of Medjool : 284\n",
      "Number of Nabtat Ali : 27\n",
      "Number of Shaishe : 209\n",
      "Number of Sokari : 325\n",
      "Number of Sugaey : 333\n"
     ]
    }
   ],
   "source": [
    "for _dir in os.listdir(parent_dir):\n",
    "    print('Number of {} :'.format(_dir),len([name for name in os.listdir(os.path.join(parent_dir,_dir)) if os.path.isfile(os.path.join(os.path.join(parent_dir,_dir), name))]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f8020a",
   "metadata": {},
   "source": [
    "## Combine datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c75f3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Combined Directory Dataset\n",
    "import shutil\n",
    "\n",
    "\n",
    "controlled_dir = '{0}\\\\dates_dataset\\\\dates_controlled_env'.format(os.getcwd())\n",
    "combined_dir = '{0}\\\\dates_dataset\\\\dataset_combined'.format(os.getcwd())\n",
    "if(not os.path.isdir(combined_dir)):\n",
    "    os.mkdir(combined_dir)\n",
    "def copyFilesToDirectory(source_dir,dist_dir):\n",
    "    for file_name in os.listdir(source_dir):\n",
    "        # construct full file path\n",
    "        source = source_dir +'\\\\'+ file_name\n",
    "        destination = dist_dir +'\\\\'+  file_name\n",
    "        # copy only files\n",
    "        if os.path.isfile(source):\n",
    "            if not os.path.exists(destination):\n",
    "                shutil.copy(source, destination)\n",
    "                print('copied', file_name)\n",
    "            else:\n",
    "                base, extension = os.path.splitext(destination)\n",
    "                i = 1\n",
    "                while os.path.exists(os.path.join(dist_dir, '{}_{}{}'.format(base, i, extension))):\n",
    "                    i += 1\n",
    "                shutil.copy(file_path, os.path.join(out_dir, '{}_{}{}'.format(base, i, extension)))\n",
    "            \n",
    "            \n",
    "for key in keywords:\n",
    "    combined_key_dir = os.path.join(combined_dir,key)\n",
    "    if (not os.path.isdir(combined_key_dir)):\n",
    "        os.mkdir(key_dir)\n",
    "    key_google_dir = os.path.join(parent_dir,key)\n",
    "    key_controlled_env_dir = os.path.join(controlled_dir,key)\n",
    "    copyFilesToDirectory(key_google_dir,combined_key_dir)\n",
    "    copyFilesToDirectory(key_controlled_env_dir,combined_key_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4fd7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Files \n",
    "\n",
    "for key in keywords:\n",
    "    path = os.path.join(combined_dir,key)\n",
    "    files = os.listdir(path)\n",
    "    for index, file in enumerate(files):\n",
    "        os.rename(os.path.join(path, file), os.path.join(path, ''.join([str(index), '.jpg'])))\n",
    "    print('All Files in {} directory has been renamed.'.format(key))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2e84a0",
   "metadata": {},
   "source": [
    "### Final Dataset Size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b92a580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ajwa Type has 517 of images\n",
      "Sokari Type has 589 of images\n",
      "Medjool Type has 419 of images\n",
      "Nabtat Ali Type has 204 of images\n",
      "Shaishe Type has 380 of images\n",
      "Sugaey Type has 501 of images\n"
     ]
    }
   ],
   "source": [
    "for key in keywords:\n",
    "    print('{0} Type has {1} of images'.format(key,len(os.listdir(os.path.join(combined_dir,key)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a647ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
